# Makefile for parallel graph connectivity algorithms
CC = gcc
CFLAGS = -O3 -Wall -fopenmp
THREAD_CONFIGS = 8

# Directories
TARGETS = slota_madduri_par jen_schmidt_par tarjan_vishkin_par
RESULTS_DIR = results_par

# Get all datasets dynamically (without .txt extension for target names)
DATASETS_FULL = $(wildcard datasets/*.txt)
DATASETS = $(patsubst datasets/%.txt,%,$(DATASETS_FULL))

# Default target
all: setup $(TARGETS) run

setup:
	@mkdir -p $(RESULTS_DIR)
	@mkdir -p bin

# Rules for each algorithm
slota_madduri_par: slota_madduri/slota_madduri_par.c
	$(CC) $(CFLAGS) -o bin/$@ $<

jen_schmidt_par: jen-schmidt/jen_schmidt_par.c
	$(CC) $(CFLAGS) -o bin/$@ $<

tarjan_vishkin_par: tarjan-viskin/tarjan_vishkin_par.c
	$(CC) $(CFLAGS) -o bin/$@ $<

# Run all algorithms on all datasets with different thread counts
run: $(foreach t,$(THREAD_CONFIGS),$(foreach d,$(DATASETS),$(foreach target,$(TARGETS),run_$(t)_$(d)_$(target))))

# Define a function to extract parts of a target name
define run_rule
run_%_$(1)_$(2): bin/$(2)
	@echo "Running $$< on $(1) dataset with $$* threads..."
	@mkdir -p $(RESULTS_DIR)
	@echo "---------------------------------------------------" > $(RESULTS_DIR)/$$*_threads_$(2)_$(1).txt
	@echo "Results for $$< on $(1) dataset with $$* threads" >> $(RESULTS_DIR)/$$*_threads_$(2)_$(1).txt
	@echo "Timestamp: $$(date)" >> $(RESULTS_DIR)/$$*_threads_$(2)_$(1).txt
	@echo "---------------------------------------------------" >> $(RESULTS_DIR)/$$*_threads_$(2)_$(1).txt
	OMP_NUM_THREADS=$$* $$< datasets/$(1).txt >> $(RESULTS_DIR)/$$*_threads_$(2)_$(1).txt 2>&1
	@echo "Completed $$< on $(1) dataset with $$* threads. Results in $(RESULTS_DIR)/$$*_threads_$(2)_$(1).txt"
endef

# Generate all the run rules for each dataset and algorithm
$(foreach d,$(DATASETS),$(foreach t,$(TARGETS),$(eval $(call run_rule,$(d),$(t)))))

# Generate summary report of all results with scaling analysis
report:
	@echo "---------------------------------------------------" > $(RESULTS_DIR)/summary_report.txt
	@echo "Summary Report for Parallel Algorithms" >> $(RESULTS_DIR)/summary_report.txt
	@echo "Generated on: $$(date)" >> $(RESULTS_DIR)/summary_report.txt
	@echo "---------------------------------------------------" >> $(RESULTS_DIR)/summary_report.txt
	@echo "" >> $(RESULTS_DIR)/summary_report.txt
	@for algo in $(TARGETS); do \
		for dataset in $(DATASETS); do \
			echo "Algorithm: $$algo - Dataset: $$dataset" >> $(RESULTS_DIR)/summary_report.txt; \
			for threads in $(THREAD_CONFIGS); do \
				echo "  Threads: $$threads" >> $(RESULTS_DIR)/summary_report.txt; \
				grep -A 1 "Computation time" $(RESULTS_DIR)/$${threads}_threads_$${algo}_$${dataset}.txt 2>/dev/null | head -2 >> $(RESULTS_DIR)/summary_report.txt || echo "  No results found" >> $(RESULTS_DIR)/summary_report.txt; \
			done; \
			echo "" >> $(RESULTS_DIR)/summary_report.txt; \
		done; \
	done
	@echo "Summary report generated at $(RESULTS_DIR)/summary_report.txt"
	@python3 -c "print('Generating scaling analysis...')"
	@echo "---------------------------------------------------" > $(RESULTS_DIR)/scaling_analysis.txt
	@echo "Scaling Analysis for Parallel Algorithms" >> $(RESULTS_DIR)/scaling_analysis.txt
	@echo "Generated on: $$(date)" >> $(RESULTS_DIR)/scaling_analysis.txt
	@echo "---------------------------------------------------" >> $(RESULTS_DIR)/scaling_analysis.txt
	@echo "" >> $(RESULTS_DIR)/scaling_analysis.txt
	@for algo in $(TARGETS); do \
		for dataset in $(DATASETS); do \
			echo "Algorithm: $$algo - Dataset: $$dataset" >> $(RESULTS_DIR)/scaling_analysis.txt; \
			echo "Threads | Computation Time | Speedup vs Sequential" >> $(RESULTS_DIR)/scaling_analysis.txt; \
			echo "--------|------------------|----------------------" >> $(RESULTS_DIR)/scaling_analysis.txt; \
			if [ -f $(RESULTS_DIR)/2_threads_$${algo}_$${dataset}.txt ]; then \
				base_time=$$(grep -A 1 "Computation time" $(RESULTS_DIR)/2_threads_$${algo}_$${dataset}.txt 2>/dev/null | tail -1 | awk '{print $$3}' || echo "0"); \
				for threads in $(THREAD_CONFIGS); do \
					if [ -f $(RESULTS_DIR)/$${threads}_threads_$${algo}_$${dataset}.txt]; then \
						time=$$(grep -A 1 "Computation time" $(RESULTS_DIR)/$${threads}_threads_$${algo}_$${dataset}.txt 2>/dev/null | tail -1 | awk '{print $$3}' || echo "0"); \
						if [ "$$base_time" != "0" ] && [ "$$time" != "0" ]; then \
							speedup=$$(echo "$$base_time / $$time" | bc -l | xargs printf "%.2f"); \
							printf "%7s | %17s | %22s\n" "$$threads" "$$time seconds" "$$speedup" >> $(RESULTS_DIR)/scaling_analysis.txt; \
						else \
							printf "%7s | %17s | %22s\n" "$$threads" "N/A" "N/A" >> $(RESULTS_DIR)/scaling_analysis.txt; \
						fi; \
					else \
						printf "%7s | %17s | %22s\n" "$$threads" "No data" "N/A" >> $(RESULTS_DIR)/scaling_analysis.txt; \
					fi; \
				done; \
			else \
				echo "  No baseline (2 threads) data available for $$algo on $$dataset dataset" >> $(RESULTS_DIR)/scaling_analysis.txt; \
			fi; \
			echo "" >> $(RESULTS_DIR)/scaling_analysis.txt; \
		done; \
	done
	@echo "Scaling analysis generated at $(RESULTS_DIR)/scaling_analysis.txt"

# Clean up all binaries and results
clean:
	rm -rf bin
	rm -rf $(RESULTS_DIR)

# Print the detected datasets (for debugging)
list-datasets:
	@echo "Detected datasets: $(DATASETS)"
	@echo "Full paths: $(DATASETS_FULL)"

.PHONY: all setup run report clean list-datasets